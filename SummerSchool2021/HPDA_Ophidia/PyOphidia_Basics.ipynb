{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial:  PyOphidia command examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all import PyOphidia modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyOphidia import cube, client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyOphidia** is a GPLv3-licensed Python module to interact with the Ophidia framework. It implements two main classes:\n",
    "   \n",
    "- **Client** class: it supports the submissions of Ophidia commands and workflows as well as the management of sessions from Python code\n",
    "- **Cube** class: it builds on the client class and provides the datacube type abstraction and the methods to manipulate, process and get information on cubes objects\n",
    "   \n",
    "While the *cube* module provides a user-friendly interface, the *client* module allows a finer specification of the operators.\n",
    "\n",
    "As a first command we need to connect to the Ophidia server front-end to load the modules variables and start an analytics session (connection details are inferred from the environment with ```read_env=true```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load a NetCDF file. We can inspect the file with the *explorenc* Ophidia operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.explorenc(\n",
    "            src_path=\"/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a datacube from the NetCDF file:\n",
    "- The file path is **/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc**\n",
    "- The variable to be imported is **tasmax**\n",
    "- Data should be arranged in order to operate on time series (```imp_dim='time'```) \n",
    "\n",
    "**Note: We are not directly reading the file content from the notebook**\n",
    "\n",
    "**Single core**: Import the input NetCDF file using 1 core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mycube = cube.Cube.importnc2(\n",
    "            src_path='/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "            measure='tasmax',\n",
    "            imp_dim='time',\n",
    "            ncores=1,\n",
    "            description=\"Imported cube (1 core)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-core**: Import the input NetCDF file using 4 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "mycube = cube.Cube.importnc2(\n",
    "            src_path='/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "            measure='tasmax',\n",
    "            imp_dim='time',\n",
    "            ncores=4,\n",
    "            description=\"Imported cube (4 cores)\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datacubes available in the virtual file system. Ophidia manages a virtual file system associated with each user that provides a hierarchical organization of concepts, supporting: \n",
    "\n",
    "* *datacubes*, the actual objects containing the data and related metadata;\n",
    "* *containers*, grouping together a set of related datacubes; \n",
    "* *virtual folders*, to store one or more containers according to the user's needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of arguments and default values we can use the python *help()* command can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cube.Cube.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the cube and its dimensions structure. Note the data fragmentation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the datacube over space (lat and lon) and time. A filter with the actual dimension values  can be provided using ```subset_type=\"coord\"```.\n",
    "\n",
    "**Note: each instance method produces a new datacube object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2 = mycube.subset(\n",
    "            subset_dims=\"lat|lon|time\",\n",
    "            subset_filter=\"-50:20|20:160|150:240\",\n",
    "            subset_type=\"coord\",\n",
    "            ncores=2,\n",
    "            description=\"Subsetted cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the new cube: the dimension sizes and fragmentation info have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does the datacube actually contain at this point? We can use the ```explore``` method to check the content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.explore(limit_filter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explore just a specific portion of the datacube. ```explore``` supports filters on multiple dimensions similarly to the subset method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2.explore(subset_dims=\"lat|lon|time\",subset_type=\"index\",subset_filter=\"1:2|1:4|1:4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the **maximum** value over the time series for each point in the spatial domain. We can also compute other metrics (see http://ophidia.cmcc.it/documentation/users/operators/OPH_REDUCE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube3 = mycube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"Reduced cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new cube the time dimension is \"collapsed\" (size: *ALL*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now reorganize the data structure by making the longitude dimension an array-oriented dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4 = mycube3.rollup(\n",
    "                ncores=2,\n",
    "                description=\"Rollup cube\"\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new cube will now have *lon* as an array-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each operation executed creates a new datacube on the framework (datacubes are not overwritten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export the data into a Python-friendly structure. \n",
    "\n",
    "**Note: this is the first time we move data from the server-side to the Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure looks something like this\n",
    "\n",
    "<img src=\"imgs/export_array.png\" alt=\"Export Array\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mycube4.export_array()\n",
    "\n",
    "from IPython.lib.pretty import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data exported in the Python structure can be used to create a map (note the definition of a Python function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotData(data):\n",
    "    \n",
    "    import cartopy.crs as ccrs\n",
    "    import matplotlib.pyplot as plt\n",
    "    from cartopy.mpl.geoaxes import GeoAxes\n",
    "    from cartopy.util import add_cyclic_point\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "    #Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=projection)\n",
    "\n",
    "    #Draw coastline and gridlines\n",
    "    ax.coastlines()\n",
    "\n",
    "    gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    lat = data['dimension'][0]['values'][ : ]\n",
    "    lon = data['dimension'][1]['values'][ : ]\n",
    "    var = data['measure'][0]['values'][ : ]\n",
    "    var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "    #Wraparound points in longitude\n",
    "    var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "    x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "    #Define color levels for color bar\n",
    "    clevs = np.arange(200,340,5)\n",
    "\n",
    "    #Set filled contour plot\n",
    "    cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.jet)\n",
    "    plt.colorbar(cnplot,ax=ax)\n",
    "\n",
    "    ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "    plt.title('Maximum Near-Surface Air Temperature (deg K)')\n",
    "    plt.show()\n",
    "    \n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results in a NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube4.exportnc2(\n",
    "    output_path=\"/home/ophidia/notebooks\",\n",
    "    output_name=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What If we want to consider the whole spatial domain and specify a subset only on the time range? \n",
    "\n",
    "We can perform the new set of operations on *mycube* object, without the need to re-import the dataset from the file. The time range can be provided in human-readable form with a datetime format setting ```time_filter=\"yes\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMycube2 = mycube.subset(\n",
    "                subset_dims=\"time\",\n",
    "                subset_filter=\"2096-01-01_2096-12-31\",\n",
    "                subset_type=\"coord\",\n",
    "                time_filter=\"yes\",\n",
    "                ncores=2,\n",
    "                description=\"New subsetted cube\"\n",
    "        )\n",
    "\n",
    "newMycube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the rerun the same operations on the new cube ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newMycube3 = newMycube2.reduce(\n",
    "                operation='max',\n",
    "                ncores=2,\n",
    "                description=\"New reduced cube\"\n",
    "            )\n",
    "\n",
    "newMycube4 = newMycube3.rollup(\n",
    "                ncores=2,\n",
    "                description=\"New rollup cube\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want to get the *minimum* instead of the maximum value?\n",
    "\n",
    "Again we can perform the new set of operations on *newMycube2* object, without the need to re-import or subset the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newNewMycube3 = newMycube2.reduce(\n",
    "                    operation='min',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube2\"\n",
    "                )\n",
    "\n",
    "newNewMycube4 = newNewMycube3.rollup(\n",
    "                    ncores=2,\n",
    "                    description=\"New rollup cube2\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newNewMycube4.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ***predicate*** evaluation operation to identify the days with temperature below a given threshold, e.g. 273.15°K (see http://ophidia.cmcc.it/documentation/users/primitives/OPH_PREDICATE.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icingdays = mycube.apply(\n",
    "    query=\"oph_predicate('OPH_FLOAT','OPH_INT',measure,'x-273.15','<0','1','0')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and count days below the given threshold on yearly basis (this is known as the *Icing Days* climate index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = icingdays.reduce2(\n",
    "    operation='sum',\n",
    "    dim='time',\n",
    "    concept_level='y',\n",
    ")\n",
    "count.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the first year from the last cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstyear = count.subset(subset_filter=1, subset_dims='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.util import add_cyclic_point\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6), dpi=100)\n",
    "\n",
    "#Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "projection = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=projection)\n",
    "\n",
    "#Draw coastline and gridlines\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "data = firstyear.export_array(show_time='yes')\n",
    "lat = data['dimension'][0]['values'][ : ]\n",
    "lon = data['dimension'][1]['values'][ : ]\n",
    "var = data['measure'][0]['values'][ : ]\n",
    "var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "#Wraparound points in longitude\n",
    "var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "#Define color levels for color bar\n",
    "levStep = (np.nanmax(var)-np.nanmin(var))/20\n",
    "clevs = np.arange(np.nanmin(var),np.nanmax(var)+levStep,levStep)\n",
    "\n",
    "#Set filled contour plot\n",
    "cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.Blues)\n",
    "plt.colorbar(cnplot,ax=ax)\n",
    "\n",
    "ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "plt.title('Icing Days (year 2096)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series processing\n",
    "\n",
    "Starting from the first imported datacube, we can extract a single time series for a given spatial point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycube2 = mycube.subset(\n",
    "            subset_dims=\"lat|lon|time\",\n",
    "            subset_filter=\"42|15|2096-01-01_2096-12-31\",\n",
    "            subset_type=\"coord\",\n",
    "            ncores=2,\n",
    "            time_filter=\"yes\",\n",
    "            description=\"Subsetted cube\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the moving average on each element of the measure array (see http://ophidia.cmcc.it/documentation/users/primitives/OPH_MOVING_AVG.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_avg = mycube2.apply(\n",
    "    query=\"oph_moving_avg('OPH_FLOAT','OPH_FLOAT',measure,7.0,'OPH_SMA')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and plot the two time series (*mycube2* and *moving_avg*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = mycube2.export_array()\n",
    "data_mov = moving_avg.export_array()\n",
    "\n",
    "y1 = data['measure'][0]['values'][0][:]\n",
    "y2 = data_mov['measure'][0]['values'][0][:]\n",
    "x = data['dimension'][2]['values'][:]\n",
    "plt.figure(figsize=(11, 3), dpi=100)\n",
    "\n",
    "plt.plot(x, y1,'r',label=\"2096\")\n",
    "plt.plot(x, y2,'g',label=\"moving_avg\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "\n",
    "plt.ylabel(data['measure'][0]['name'] + \" (degK)\")\n",
    "\n",
    "plt.xlabel(\"Days since 2096/01/01\")\n",
    "plt.title('Maximum Near-Surface Air Temperature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare two time series.**\n",
    "\n",
    "We can also compute the difference between two time series (also from different cubes). \n",
    "\n",
    "Let's first compute the average value over the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCube = mycube.reduce2(\n",
    "    operation='avg',\n",
    "    dim='time',\n",
    "    concept_level='M',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first time series (2096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstYear = avgCube.subset(\n",
    "                subset_dims=\"lat|lon|time\", \n",
    "                subset_type=\"coord\", \n",
    "                subset_filter=\"42|15|2096-01-01_2096-12-31\",\n",
    "                ncores=2,\n",
    "                time_filter=\"yes\",\n",
    "                description=\"Subsetted cube (2096)\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the second time series (2097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondYear = avgCube.subset(\n",
    "                subset_dims=\"lat|lon|time\", \n",
    "                subset_type=\"coord\", \n",
    "                subset_filter=\"42|15|2097-01-01_2097-12-31\",\n",
    "                ncores=2,\n",
    "                time_filter=\"yes\",\n",
    "                description=\"Subsetted cube (2097)\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the strcuture for the 2nd cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondYear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the difference between 2097 and 2096 monthly-mean time series. The **intercube** operator provides other types of inter-cube operations (http://ophidia.cmcc.it/documentation/users/operators/OPH_INTERCUBE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = secondYear.intercube(cube2=firstYear.pid,operation=\"sub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = diff.export_array()\n",
    "\n",
    "y = data['measure'][0]['values'][0][:]\n",
    "x = data['dimension'][2]['values'][:]\n",
    "plt.figure(figsize=(11, 5), dpi=100)\n",
    "plt.grid(zorder=0)\n",
    "plt.bar(x, y, width=10, zorder=2)\n",
    "\n",
    "plt.ylabel(data['measure'][0]['name'] + \" difference (degC)\")\n",
    "plt.title('Maximum Near-Surface Air Temperature - difference 2097-2096')\n",
    "plt.xticks(x, ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'], rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workspace now contains several datacubes from the experiments just run. Once done, we can clear the space before moving to other notebooks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.deletecontainer(container='tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The virtual file system should now be \"clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
