{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo tutorial:  PyOphidia command examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PyOphidia** is a GPLv3-licensed Python module to interact with the Ophidia framework. It implements two main classes:\n",
    "   \n",
    "- **Client** class: it supports the submissions of Ophidia commands and workflows as well as the management of sessions from Python code\n",
    "- **Cube** class: it builds on the client class and provides the datacube type abstraction and the methods to manipulate, process and get information on cubes objects\n",
    "   \n",
    "While the *cube* module provides a user-friendly interface, the *client* module allows a finer specification of the operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all import PyOphidia modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyOphidia import cube, client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first command we need to connect to the Ophidia server front-end to load the modules variables and start an analytics session.\n",
    "So, we instantiate a new Client common to all Cube instances using *setclient* method (connection details are inferred from the environment with ```read_env=true```)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load a NetCDF file. We can inspect the file with the *explorenc* Ophidia operator that shows:\n",
    "- *Dimension list*: it contains the NetCDF file dimensions and their size;\n",
    "- *Variable list*: it includes the NetCDF file variables, their type and the related dimensions;\n",
    "- *Metadata list*: it shows file attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.explorenc(\n",
    "            src_path=\"/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a datacube from a CMIP5 NetCDF (.nc) dataset produced by [*CMCC Foundation*](https://www.cmcc.it) with the CESM model  using the *importnc* operator with the following parameters:\n",
    "- *src_path*: contains the file path **/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc**\n",
    "-  ```measure='tasmax'```: it represents the variable to be imported (**tasmax**)\n",
    "- ```imp_dim='time'```: it means that data should be arranged in order to operate on time series\n",
    "- *ncores*: it is the number of cores to be used\n",
    "- *nfrag*: it is the number of fragments \n",
    "- *description*: it represents the description associated to the datacube\n",
    "\n",
    "**Note: We are not directly reading the file content from the notebook**\n",
    "\n",
    "**Single core**: Import the input NetCDF file using 1 core and 4 fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tasmaxCube = cube.Cube.importnc2(\n",
    "            src_path='/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "            measure='tasmax',\n",
    "            imp_dim='time',\n",
    "            ncores=1,\n",
    "            nfrag=4,\n",
    "            description=\"Imported cube (1 core)\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-core**: Import the input NetCDF file using 4 cores and 4 fragments. This time the operator will run the import with 4 parallel processes and the execution time should take less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tasmaxCube = cube.Cube.importnc2(\n",
    "            src_path='/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "            measure='tasmax',\n",
    "            imp_dim='time',\n",
    "            ncores=4,\n",
    "            nfrag=4,\n",
    "            description=\"Imported cube (4 cores)\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the datacubes available in the virtual file system. Ophidia manages a virtual file system associated with each user that provides a hierarchical organization of concepts, supporting: \n",
    "\n",
    "* *datacubes*, the actual objects containing the data and related metadata;\n",
    "* *containers*, grouping together a set of related datacubes; \n",
    "* *virtual folders*, to store one or more containers according to the user's needs. \n",
    "\n",
    "In particular, we can use the *list* operator with the level of verbosity parameter (```level=2``` shows folders, containers and datacubes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the list of arguments and default values the python *help()* command can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cube.Cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the cube and its dimensions structure using the *info* method. Note the data fragmentation table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset the datacube over space (lat and lon) and time specifying ```subset_dims=\"lat|lon|time\"```. A filter with the actual dimension values (e.g ```subset_filter=\"-50:20|20:160|JJA\"```) can be provided using ```subset_type=\"coord\"```.\n",
    "\n",
    "**Note: each instance method produces a new datacube object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2 = tasmaxCube.subset(\n",
    "            subset_dims=\"lat|lon|time\",\n",
    "            subset_filter=\"-50:20|20:160|JJA\",\n",
    "            subset_type=\"coord\",\n",
    "            time_filter=\"yes\",\n",
    "            ncores=2,\n",
    "            description=\"Subsetted cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the new cube: the dimension sizes and fragmentation info have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what does the datacube actually contain at this point? We can use the *explore* method to check the content. The ```limit_filter=1``` option allows to show only one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2.explore(limit_filter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also explore just a specific portion of the datacube. The *explore* operator supports filters on multiple dimensions similarly to the subset method. ```subset_type=\"index\"``` allows to filter on dimension index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2.explore(subset_dims=\"lat|lon|time\",subset_type=\"index\",subset_filter=\"1:2|1:4|1:4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the **maximum** value over the time series for each point in the spatial domain using ```operation='max'```. We can also compute other metrics (see http://ophidia.cmcc.it/documentation/users/operators/OPH_REDUCE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube3 = tasmaxCube2.reduce(\n",
    "                    operation='max',\n",
    "                    ncores=2,\n",
    "                    description=\"Reduced cube\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the new cube the time dimension is \"collapsed\" (size: *ALL*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Each operation executed creates a new datacube on the framework (datacubes are not overwritten)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's export the data into a Python-friendly structure with the *export_array()* method. \n",
    "\n",
    "**Note: this is the first time we move data from the server-side to the Notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tasmaxCube3.export_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure looks something like this\n",
    "\n",
    "<img src=\"imgs/export_array.png\" alt=\"Export Array\" width=\"800\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data exported in the Python structure can be used to create a map (note the definition of a Python function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def plotData(data):\n",
    "    \n",
    "    import cartopy.crs as ccrs\n",
    "    import matplotlib.pyplot as plt\n",
    "    from cartopy.mpl.geoaxes import GeoAxes\n",
    "    from cartopy.util import add_cyclic_point\n",
    "    import numpy as np\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "    #Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=projection)\n",
    "\n",
    "    #Draw coastline and gridlines\n",
    "    ax.coastlines()\n",
    "\n",
    "    gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    lat = data['dimension'][0]['values'][ : ]\n",
    "    lon = data['dimension'][1]['values'][ : ]\n",
    "    var = data['measure'][0]['values'][ : ]\n",
    "    var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "    #Wraparound points in longitude\n",
    "    var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "    x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "    #Define color levels for color bar\n",
    "    clevs = np.arange(200,340,5)\n",
    "\n",
    "    #Set filled contour plot\n",
    "    cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.jet)\n",
    "    plt.colorbar(cnplot,ax=ax)\n",
    "    \n",
    "    #Set the aspect of the axis scaling\n",
    "    ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "    plt.title('Maximum Near-Surface Air Temperature (deg K)')\n",
    "    plt.show()\n",
    "    \n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results in a NetCDF file using the *exportnc* operator with the following parameters:\n",
    "- *output_path*: represents the destination path (**/home/ophidia/notebooks/**)\n",
    "- *output_name*: is the name of the output NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube3.exportnc2(\n",
    "    output_path=\"/home/ophidia/notebooks/\",\n",
    "    output_name='max'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What If we want to consider the whole spatial domain and specify a subset only on the time range? \n",
    "\n",
    "We can perform the new set of operations on *mycube* object, without the need to re-import the dataset from the file. The time range can be provided in human-readable form with a datetime format (e.g ```subset_filter=\"2096-01-01_2097-01-01\"```) setting ```time_filter=\"yes\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2 = tasmaxCube.subset(\n",
    "                subset_dims=\"time\",\n",
    "                subset_filter=\"2096-01-01_2096-12-31\",\n",
    "                subset_type=\"coord\",\n",
    "                time_filter=\"yes\",\n",
    "                ncores=2,\n",
    "                description=\"New subsetted cube\"\n",
    "        )\n",
    "\n",
    "tasmaxCube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can rerun the same operation on the new cube ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube3 = tasmaxCube2.reduce(\n",
    "                operation='max',\n",
    "                ncores=2,\n",
    "                description=\"New reduced cube\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tasmaxCube3.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we want to get the *minimum* instead of the maximum value?\n",
    "\n",
    "Again we can apply the *reduce* operator with ```operation='min'``` on *newMycube2* object, without the need to re-import or subset the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube3 = tasmaxCube2.reduce(\n",
    "                    operation='min',\n",
    "                    ncores=2,\n",
    "                    description=\"New reduced cube2\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and plot the new datacube values on a map using the function *plotData*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tasmaxCube3.export_array()\n",
    "plotData(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can import the NetCDF file for the tasmin variable... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasminCube = cube.Cube.importnc2(\n",
    "            src_path='/home/ophidia/notebooks/tasmin_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "            measure='tasmin',\n",
    "            imp_dim='time',\n",
    "            ncores=4,\n",
    "            nfrag=4,\n",
    "            description=\"Imported cube\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the ***predicate*** evaluation operation into the *apply* operator in order to identify the days with temperature over a given threshold, e.g. 293.15째K (see http://ophidia.cmcc.it/documentation/users/primitives/OPH_PREDICATE.html). \n",
    "\n",
    "Basically, we put to 1 the temperatures over 293.15째K (20째C), 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasminCube2 = tasminCube.apply(\n",
    "    query=\"oph_predicate('OPH_FLOAT','OPH_INT',measure,'x-293.15','>0','1','0')\",\n",
    "    ncores=4\n",
    ")\n",
    "tasminCube2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and count days over the given threshold on yearly basis. This is known as the **Tropical Nights index**: starting from the daily minimum temperature (2096-2100) TN, the Tropical Nights index is the number of days where $TN > T$ (T is  a reference temperature, e.g. 20째C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropicalNights = tasminCube2.reduce2(\n",
    "    operation='sum',\n",
    "    dim='time',\n",
    "    concept_level='y',\n",
    "    ncores=4\n",
    ")\n",
    "tropicalNights.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the *to_dataset* method in order to export the datacube into an **Xarray dataset**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropicalNights_ds = tropicalNights.to_dataset().transpose('time','lat','lon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the result that consists of the *tasmin* variable, coordinates and attributes which together form a self describing dataset (see https://docs.xarray.dev/en/stable/generated/xarray.Dataset.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tropicalNights_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot all years from the dataset using **Matplotlib** and **Cartopy**. Basically, it is the same code of the *plotData* function with in addition the animation function that allows to flow the maps over years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.util import add_cyclic_point\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def drawmap(ax,x,y,var_cyclic, clevs, title):\n",
    "    ax.set_title(title, fontsize=14)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    #Draw coastline and gridlines\n",
    "    ax.coastlines()\n",
    "    gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "    #Set filled contour plot\n",
    "    cs = ax.contourf(x, y, var_cyclic, clevs, cmap=plt.cm.Oranges)\n",
    "    return cs\n",
    "    \n",
    "def myanimate(i, ax, dataset, values, lat, lon, x, y, var_cyclic, clevs):\n",
    "    from datetime import datetime\n",
    "    ax.clear()\n",
    "    # change var_cyclic...\n",
    "    var = values[i]\n",
    "    var = np.reshape(var, (len(lat), len(lon)))\n",
    "    #Wraparound points in longitude\n",
    "    var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "    x, y = np.meshgrid(lon_cyclic,lat)\n",
    "    year = datetime.fromisoformat(dataset['time'].values[i]).year\n",
    "    new_contour = drawmap(ax,x,y,var_cyclic, clevs, year) \n",
    "    return new_contour\n",
    "\n",
    "\n",
    "def plotData(dataset):\n",
    "    lat = dataset['lat'].values\n",
    "    lon = dataset['lon'].values\n",
    "    values = dataset['tasmin'].values\n",
    "    max=dataset.tasmin.max()\n",
    "    min=dataset.tasmin.min()\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=100)\n",
    "\n",
    "    #Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "    projection = ccrs.PlateCarree()\n",
    "    ax = plt.axes(projection=projection)\n",
    "\n",
    "    #Draw coastline and gridlines\n",
    "    ax.coastlines()\n",
    "    gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    var = values[0]\n",
    "    var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "    #Wraparound points in longitude\n",
    "    var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "    x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "    #Define color levels for color bar\n",
    "    levStep = (max-min)/20\n",
    "    clevs = np.arange(min,max+levStep,levStep)\n",
    "\n",
    "    #Set filled contour plot\n",
    "    first_contour = drawmap(ax,x,y,var_cyclic, clevs, dataset['time'].values[0]) \n",
    "\n",
    "    #Make a color bar\n",
    "    plt.colorbar(first_contour, fraction=0.047*0.493)\n",
    "    \n",
    "    #Set the aspect of the axis scaling\n",
    "    ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "    #Execute the myanimate function that change maps over time\n",
    "    ani = animation.FuncAnimation(fig, myanimate, fargs=(ax, dataset, values, lat, lon, x, y, var_cyclic, clevs), frames=np.arange(5), interval=500)\n",
    "    return HTML(ani.to_jshtml())\n",
    "\n",
    "plotData(tropicalNights_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series processing\n",
    "\n",
    "Starting from the first imported datacube, we can extract a single time series for a given spatial point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2 = tasmaxCube.subset(\n",
    "            subset_dims=\"lat|lon|time\",\n",
    "            subset_filter=\"42|15|2096-01-01_2096-12-31\",\n",
    "            subset_type=\"coord\",\n",
    "            ncores=2,\n",
    "            time_filter=\"yes\",\n",
    "            description=\"Subsetted cube\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the moving average on each element of the measure array using the *apply* operator with the *oph_moving_avg* primitive (see http://ophidia.cmcc.it/documentation/users/primitives/OPH_MOVING_AVG.html).\n",
    "\n",
    "**Note: the moving average is defined as an average of fixed number of items in the time series**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingAvg = tasmaxCube2.apply(\n",
    "    query=\"oph_moving_avg('OPH_FLOAT','OPH_FLOAT',measure,7.0,'OPH_SMA')\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the datacubes into Xarray datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasmaxCube2_ds = tasmaxCube2.to_dataset()\n",
    "tasmaxCube2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingAvg_ds = movingAvg.to_dataset()\n",
    "movingAvg_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and plot the two time series (*tasmaxCube2_ds* and *movingAvg_ds*) using the **Bokeh Visualization library** (see https://bokeh.org). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.models import ColumnDataSource, Legend, DatetimeTickFormatter, DatetimeTicker, Range1d, HoverTool\n",
    "labels = []\n",
    "for t in tasmaxCube2_ds['time'].values:\n",
    "    labels.append(datetime.strptime(str(t).split(\" \")[0], '%Y-%m-%d'))\n",
    "# Set ColumnDataSource for each metric\n",
    "source_metrics = {'time': labels, '2096': tasmaxCube2_ds.tasmax.values.flatten(), \n",
    "                  'moving_avg': movingAvg_ds.tasmax.values.flatten()}\n",
    "source = ColumnDataSource(data = source_metrics)\n",
    "# Create the right number of ticks on the x axis so as not to make them overlap\n",
    "date_values = []\n",
    "start_date = labels[0]\n",
    "end_date = labels[-1]\n",
    "delta = timedelta(days=1)\n",
    "while start_date <= end_date:\n",
    "    date_values.append(start_date)\n",
    "    start_date += delta\n",
    "if len(date_values)>50:\n",
    "    number_ticks = 50\n",
    "else: \n",
    "    number_ticks = len(date_values)\n",
    "# Create figure and time series:\n",
    "p = figure(x_axis_type = 'datetime', y_axis_label = 'tasmax (degK)', \n",
    "           plot_height=400, plot_width=950, title=\"Maximum Near-Surface Air Temperature\")\n",
    "\n",
    "r1 = p.line(x='time', y='2096', line_width=2, color=\"#ff66cc\", source=source)\n",
    "r2 = p.line(x='time', y='moving_avg', line_width=2, color=\"#00cc99\", source=source)\n",
    "\n",
    "# Set legend\n",
    "legend = Legend(items=[(\"2096\", [r1]), (\"moving_avg\", [r2])], location=\"top_right\")\n",
    "p.add_layout(legend, 'right')\n",
    "# Set some properties to make plot better\n",
    "p.legend.click_policy=\"hide\"\n",
    "p.xgrid.grid_line_color = None\n",
    "p.xaxis.axis_label = \"Time\"\n",
    "p.xaxis.major_label_orientation = 1.2\n",
    "\n",
    "# Format x axis \n",
    "x_range = Range1d(labels[0].timestamp()*1000, labels[-1].timestamp()*1000)\n",
    "p.x_range= x_range\n",
    "p.xaxis.formatter=DatetimeTickFormatter(days=\"%Y-%m-%d\", months=\"%Y-%m-%d\", hours=\"%Y-%m-%d\", minutes=\"%Y-%m-%d\")\n",
    "p.xaxis.ticker = DatetimeTicker(desired_num_ticks=number_ticks)\n",
    "\n",
    "# Add hover tooltip\n",
    "p.add_tools(HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'time',  '@time{%F}'   ),\n",
    "        ( '2096',  '@2096' ),\n",
    "        ( 'moving_avg', '@moving_avg'),\n",
    "    ],\n",
    "    formatters={'@time': 'datetime'},\n",
    "    mode='vline',\n",
    "    renderers=[r1]\n",
    "))\n",
    "output_notebook()\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare two time series.**\n",
    "\n",
    "We can also compute the difference between two time series (also from different cubes). \n",
    "\n",
    "Let's first compute the monthly average over the time series using the *reduce2* operator with ```operation='avg'``` and ```concept_level='M'```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgCube = tasmaxCube.reduce2(\n",
    "    operation='avg',\n",
    "    dim='time',\n",
    "    concept_level='M',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first time series (2096) using the *subset* operator with fixed latitude and longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstYear = avgCube.subset(\n",
    "                subset_dims=\"lat|lon|time\", \n",
    "                subset_type=\"coord\", \n",
    "                subset_filter=\"42|15|2096-01-01_2096-12-31\",\n",
    "                ncores=2,\n",
    "                time_filter=\"yes\",\n",
    "                description=\"Subsetted cube (2096)\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same way, extract the second time series (2097)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondYear = avgCube.subset(\n",
    "                subset_dims=\"lat|lon|time\", \n",
    "                subset_type=\"coord\", \n",
    "                subset_filter=\"42|15|2097-01-01_2097-12-31\",\n",
    "                ncores=2,\n",
    "                time_filter=\"yes\",\n",
    "                description=\"Subsetted cube (2097)\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the structure for the 2nd cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondYear.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the difference between 2097 and 2096 monthly-mean time series. The **intercube** operator provides other types of inter-cube operations (http://ophidia.cmcc.it/documentation/users/operators/OPH_INTERCUBE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffCube = secondYear.intercube(cube2=firstYear.pid,operation=\"sub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the datacube into a dataset structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffCube_ds = diffCube.to_dataset()\n",
    "diffCube_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally plot the result with Bokeh library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = diffCube_ds.tasmax.values\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "source_metrics = {'time': months, 'values': values.flatten()}\n",
    "source = ColumnDataSource(data = source_metrics)\n",
    "p1 = figure(x_range = months, y_axis_label = 'tasmax difference (degC)', plot_height=400, plot_width=950, \n",
    "            title=\"Maximum Near-Surface Air Temperature - difference 2097-2096\")\n",
    "v = p1.vbar(x='time', top='values', width=0.3, source=source)\n",
    "# Set some properties to make plot better\n",
    "p1.xaxis.axis_label = \"Time\"\n",
    "p1.xaxis.major_label_orientation = 1.2\n",
    "p1.xaxis.major_label_text_font_size=\"13px\"\n",
    "# Add hover tooltip\n",
    "p1.add_tools(HoverTool(\n",
    "    tooltips=[\n",
    "        ( 'month',  '@time'   ),\n",
    "        ( 'difference',  '@values' ),\n",
    "    ],\n",
    "    mode='vline',\n",
    "    renderers=[v]\n",
    "))\n",
    "output_notebook()\n",
    "show(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our workspace now contains several datacubes from the experiments just run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done, we can clear the space before moving to other notebooks using the *deletecontainer* method with the container name (e.g ```container='tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc'```). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.deletecontainer(container='tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')\n",
    "cube.Cube.deletecontainer(container='tasmin_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The virtual file system should now be \"clean\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
