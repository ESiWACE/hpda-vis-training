{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyOphidia\n",
    "\n",
    "This notebook guides you through the implementation and execution of a sample climate indicator exploiting the **PyOphidia** module, as shown in the demo.\n",
    "\n",
    "The goal of this training is to give an overview of the features while implementing a real indicator from the *extreme climate indices* set. The indicator that you're going to implement during this training is the *Daily temperature range (DTR)*: i.e. the monthly mean difference between the maximum and minimum daily temperatures. The full list of indices is provided at [http://etccdi.pacificclimate.org/list_27_indices.shtml](http://etccdi.pacificclimate.org/list_27_indices.shtml).\n",
    "\n",
    "Before starting the actual implementation of the indicator, let's play a little with the basic features of PyOphidia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting started with PyOphidia\n",
    "\n",
    "PyOphidia is a Python package used to interact with the Ophidia Framework and it provides a convenient way to submit requests to an Ophidia server or to develop your own application using Python. It runs on Python 2 or 3 and provides 2 main modules:\n",
    "\n",
    "* client.py: low level class to submit any type of requests (simple tasks and workflows);\n",
    "* cube.py: high level cube-oriented class to interact directly with cubes.\n",
    "\n",
    "This tutorial will mainly exploit the cube class feature.\n",
    "\n",
    "Before running any other operation, a new session with the Ophidia Server must be established. Run the following code cell to set a new connection by pressing the **play** button on the top bar or **[shift + enter] keys**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyOphidia import cube\n",
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If successful, the output will show something like:\n",
    "    \n",
    "```python\n",
    "Current cdd is /\n",
    "Current session is https://127.0.0.1/ophidia/sessions/456546436462436547544775644646/experiment\n",
    "Current cwd is /\n",
    "The last produced cube is https://127.0.0.1/ophidia/1/1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the connection has been established, it's possible to run the actual data management and analytics operators. \n",
    "\n",
    "The first operator to test is *list*, which provides a graphical (ASCII-based) view of the data available in the user's space. The option ```level=2``` represents the level of verbosity. \n",
    "\n",
    "If this is the first experiment you're running, your space should be empty, otherwise you'll see some Ophidia containers/datacubes created in the previous sessions. Try it yourself by running the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to load the first dataset into your space by exploiting the *importnc* operator. Run the following command to load a CMIP5 NetCDF (*.nc*) dataset produced by [*CMCC Foundation*](https://www.cmcc.it) with the *CESM model* creating a new datacube. It should take a few seconds.\n",
    "\n",
    "As you can see, the method uses a lot of different arguments to load the data. The two most important are:\n",
    "\n",
    "* *src_path*, the path of the file to be imported\n",
    "* *measure*, the variable to be imported (*tasmax*, the maximum daily temperature)\n",
    "\n",
    "If you want to learn more about all the parameters available in the *importnc* operator, you can check the [documentation page](http://ophidia.cmcc.it/documentation/users/operators/OPH_IMPORTNC.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tasmax = cube.Cube.importnc(\n",
    "    src_path='/home/ophidia/notebooks/tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "    measure='tasmax',\n",
    "    imp_dim='time',\n",
    "    ncores=1,\n",
    "    description='Max Temperatures',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now import the second dataset related to the *tasmin* variable, i.e. the minimum daily temperature. \n",
    "\n",
    "Note the different value used for the **ncores** parameter. The Ophidia Framework provides an environment for the execution of parallel data analytics exploiting the underlying cluster features. This time the operator will run the import with 4 parallel processes and the execution time should take less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "tasmin = cube.Cube.importnc(\n",
    "    src_path='/home/ophidia/notebooks/tasmin_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',\n",
    "    measure='tasmin',\n",
    "    imp_dim='time',\n",
    "    ncores=4,\n",
    "    description='Min Temperatures',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage you should have at least 2 containers and 2 datacubes inside your space. You can run again the *list* operator to verify this yourself. Datacubes are identified by a string that looks like:  `https://127.0.0.1/ophidia/1/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you observe carefully the last two executed python lines, you'll notice that the methods are called in a slightly different way. \n",
    "\n",
    "In fact, all operators that create a new datacube in the user's space, like *importnc*, are categorized as *data operators* and produce as output a python Object enclosing the information regarding that datacube. In this way, it is possible to apply operators directly on the cube Object without the necessity to refer to the datacube identifier.\n",
    "\n",
    "On the other hand, the operators that don't create a datacube, such as *list*, are categorized as *metadata operators* and are actually Class Methods that simply produce a visual output without any callable Object.\n",
    "\n",
    "You're now ready to run some analytical operations on the newly imported datacubes. The next section will guide you through some basic data analysis operations required for the DTR indicator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Running data analytics operations\n",
    "\n",
    "You can run different type of operations on the datacubes available in your space. Ophidia provides around 50 data and metadata operators supporting operations including: data aggregations, complex mathematical operations, predicate evaluation, subsetting, datacube intercomparison, metadata management, as well as import and export of datacubes ([check this page for the full list](http://ophidia.cmcc.it/documentation/users/operators/index.html)).\n",
    "\n",
    "Operators applied to datacubes require a python Object referencing that cube. In the last code block we created the **tasmin** cube Object, so now we can apply other operations to this datacube.\n",
    "\n",
    "The following cell code will perform a simple data reduction operation (i.e. the average over the whole time range) on the **tasmin** cube Object and produce another cube Object called **testCube1**. The parameters in the function specify the type of operations to be performed. In particular:\n",
    "\n",
    "* *concept_level*: represents the concept level used for the operation\n",
    "* *operation*: specify the reduction operation (*avg*, the average)\n",
    "\n",
    "\n",
    "The following commands show the information related to this newly created datacube and a portion of its content (with the option ```limit_filter=1```) (note that these don't create any new datacube)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCube1 = tasmin.reduce2(\n",
    "    dim='time',\n",
    "    concept_level='A',\n",
    "    operation='avg',\n",
    "    description=\"Overall average tasmin\",\n",
    "    ncores=2    \n",
    ")\n",
    "\n",
    "testCube1.info()\n",
    "testCube1.explore(limit_filter=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also compute other types of statistical values over different time ranges. The *reduce2* operator [documentation page](http://ophidia.cmcc.it/documentation/users/operators/OPH_REDUCE2.html) provides the full description of the alternatives implemented by the operator.\n",
    "\n",
    "Try to rerun the code above by replacing the following arguments to get the maximum temperature on a yearly basis and check the difference in the *Dimension Information* section.\n",
    "* concept_level='y'\n",
    "* operation='max'\n",
    "\n",
    "Operations can also be applied in cascade in a single line of code, like in the following line, which computes the average over all datacube dimensions. The resulting **testCube2** Object will reference the final datacube created by the sequence of operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testCube2 = tasmin.reduce(operation='avg', ncores=2).merge().aggregate(operation='avg', description=\"Mean tasmin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the Ophidia data operators working on datacubes are applied on a cube Object and produce another cube Object, however some operators require more than one input datacube, like the *intercomparison*. In this case the additional datacubes must be specified in specific arguments. \n",
    "\n",
    "Let's get back to the implementation of the DTR indicator exploiting the concepts that you've just learned. The following code will compute the daily temperature range with the *intecomparison* operator, i.e. the difference among the **tasmax** datacube and the **tasmin** datacube, creating a new cube Object called **dailyDTR**. The second datacube is specified in the *cube2* argument, while the difference is specified by the ```operation='sub'```. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The second operator computes the monthly mean values from the daily temperature ranges (setting ```concept_level='M'``` and ```operation='avg'```) in the *reduce2* operator, creating a new Object **monthlyDTR**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dailyDTR = tasmax.intercube(\n",
    "    cube2=tasmin.pid,\n",
    "    operation='sub',\n",
    "    description=\"Daily DTR\",\n",
    "    measure='dtr',\n",
    "    ncores=2\n",
    "    )\n",
    "\n",
    "monthlyDTR = dailyDTR.reduce2(\n",
    "    dim='time',\n",
    "    concept_level='M',\n",
    "    operation='avg',\n",
    "    description=\"Monthly DTR\",\n",
    "    ncores=2    \n",
    "    )\n",
    "\n",
    "monthlyDTR.explore(limit_filter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting the results of the computation\n",
    "\n",
    "Ophidia allows exporting the datacube as a NetCDF file and, thanks to the seamless integration with the python environment, it is possible to export it in python-friendly structures and plot it using well-known python modules, such as Matplotlib and Cartopy.\n",
    "\n",
    "The datacube created in the previous step (**monthlyDTR**) contains the data for several months in the time range [2096-2100]. We would like to plot the data on a map so, for the sake of simplicity, let's extract a single time step (in the example *January 2096*) using the *subset* operator with the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstMonthDTR = monthlyDTR.subset(\n",
    "    subset_dims='time',\n",
    "    subset_filter='2096-01',\n",
    "    description=\"Subset Monthly DTR\",\n",
    "    subset_type='coord',\n",
    "    ncores = 4\n",
    ")\n",
    "\n",
    "data = firstMonthDTR.export_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final row of the cell above allows exporting the data related to the **firstMonthDTR** datacube in a python-friendly structure, which can then be used as input for the plotting libraries.\n",
    "\n",
    "You can explore the info contained in this structure with the following command. As you can see, the structure contains an array of values for each dimension (i.e. *lat*, *lon*, *time*) and variable (*dtr*) belonging to the datacube."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.lib.pretty import pprint\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the *to_dataset* method in order to export the datacube into an **Xarray dataset**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = firstMonthDTR.to_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's create a simple map with the DTR data extracted so far. The following code will create a map exploiting Matplotlib and Cartopy libraries showing the DTR for the various points on the globe. \n",
    "\n",
    "You're free to change the properties to update the graphical layout. Check the Cartopy documentation for additional examples ([https://scitools.org.uk/cartopy/docs/latest/gallery/index.html](https://scitools.org.uk/cartopy/docs/latest/gallery/index.html)).\n",
    "\n",
    "Note how the values from the dimensions *lat* and *lon* are used to define the map grid.\n",
    "\n",
    "To plot the map, we can use the array obtained from the *export_array()* method ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.util import add_cyclic_point\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6), dpi=100)\n",
    "\n",
    "#Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "projection = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=projection)\n",
    "\n",
    "#Draw coastline and gridlines\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "lat = data['dimension'][0]['values'][ : ]\n",
    "lon = data['dimension'][1]['values'][ : ]\n",
    "var = data['measure'][0]['values'][ : ]\n",
    "var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "#Wraparound points in longitude\n",
    "var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "#Define color levels for color bar\n",
    "levStep = (np.nanmax(var)-np.nanmin(var))/20\n",
    "clevs = np.arange(np.nanmin(var),np.nanmax(var)+levStep,levStep)\n",
    "\n",
    "#Set filled contour plot\n",
    "cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.YlOrRd)\n",
    "plt.colorbar(cnplot,ax=ax)\n",
    "\n",
    "ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "plt.title('DTR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or the dataset obtained from *to_dataset()* method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy.mpl.geoaxes import GeoAxes\n",
    "from cartopy.util import add_cyclic_point\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6), dpi=100)\n",
    "\n",
    "#Add Geo axes to the figure with the specified projection (PlateCarree)\n",
    "projection = ccrs.PlateCarree()\n",
    "ax = plt.axes(projection=projection)\n",
    "\n",
    "#Draw coastline and gridlines\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='black', alpha=0.9, linestyle=':')\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "\n",
    "lat = dataset['lat'].values\n",
    "lon = dataset['lon'].values\n",
    "var = dataset['dtr'].values\n",
    "var = np.reshape(var, (len(lat), len(lon)))\n",
    "\n",
    "#Wraparound points in longitude\n",
    "var_cyclic, lon_cyclic = add_cyclic_point(var, coord=np.asarray(lon))\n",
    "x, y = np.meshgrid(lon_cyclic,lat)\n",
    "\n",
    "#Define color levels for color bar\n",
    "levStep = (np.nanmax(var)-np.nanmin(var))/20\n",
    "clevs = np.arange(np.nanmin(var),np.nanmax(var)+levStep,levStep)\n",
    "\n",
    "#Set filled contour plot\n",
    "cnplot = ax.contourf(x, y, var_cyclic, clevs, transform=projection,cmap=plt.cm.YlOrRd)\n",
    "plt.colorbar(cnplot,ax=ax)\n",
    "\n",
    "ax.set_aspect('auto', adjustable=None)\n",
    "\n",
    "plt.title('DTR')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final remarks\n",
    "\n",
    "Congrats! You've completed this training regarding some basics operations that can be performed with PyOphidia.\n",
    "\n",
    "If you want to clear your user space before running other notebooks, run the following commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.deletecontainer(container='tasmin_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')\n",
    "cube.Cube.deletecontainer(container='tasmax_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc',force='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move to the second tutorial notebook [**Summer Days**](2-Summer_Days.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
