{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic workflow composition with Ophidia\n",
    "\n",
    "This notebook provides a very simple example of how to build an Ophidia workflow and submit it by reusing some of the concepts shown during the demo. \n",
    "\n",
    "A workflow allows users to code a set of data processing and analytics steps into reusable documents. Moreover, the workflow manager can optimize the workflow execution to run concurrently independent operations (tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Preliminary steps\n",
    "\n",
    "As first step, let's connect to the Ophidia Server. The **PyOphidia** module and the **ESDM-PAV Client** module will be used to submit the workflow to the Ophidia workflow manager for the computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esdm_pav_client import Workflow, Experiment, Task\n",
    "import sys\n",
    "from PyOphidia import cube,client\n",
    "cube.Cube.setclient(read_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will be using a single NetCDF file produced by the CMCC-CESM model and related to the tasmin variable for the period 2096-2100. The file is located under ```/home/ophidia/notebooks/```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "glob.glob('/home/ophidia/notebooks/tasmin_*.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Workflow composition\n",
    "\n",
    "The workflow in this example consists of four sequential tasks:\n",
    "\n",
    "1. Creation of a container for the datacubes \n",
    "2. Import of the NetCDF file\n",
    "3. Extraction of a multi-dimensional subset\n",
    "4. Computation of the average over the time series\n",
    "\n",
    "The overall workflow structure is the following:\n",
    "    \n",
    "<img src=\"../imgs/Example_workflow.svg\" alt=\"Example_workflow\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define global arguments\n",
    "\n",
    "First of all we need to define the global arguments of the workflow and in particular its ```name``` and its ```execution_mode``` as shown in the following code.\n",
    "\n",
    "```sync``` means that when submitting the workflow the function will block until the execution is completed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1 = Experiment(\n",
    "    name= \"Example workflow\",\n",
    "    author= \"CMCC\",\n",
    "    abstract= \"Example workflow\",\n",
    "    exec_mode= \"sync\",\n",
    "    ncores=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the tasks\n",
    "\n",
    "The first task of the workflow is the *oph_createcontainer* operator to create an empty container to organize all the datacubes imported and produced during the workflow execution.\n",
    "\n",
    "The ```on_error``` argument is set to ```skip``` in order to simply skip the task in case of error; for example if a container of the same name already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = e1.newTask(name=\"Create container\",\n",
    "                type=\"ophidia\",\n",
    "                operator='oph_createcontainer',\n",
    "                on_error='skip',\n",
    "                arguments={'container': 'example',\n",
    "                           'dim': 'lat|lon|time',\n",
    "                           'dim_type': 'double|double|double',\n",
    "                           'hierarchy': 'oph_base|oph_base|oph_time'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second task defined is the *oph_importnc* operator to load data from a NetCDF into an Ophidia datacube.\n",
    "\n",
    "In this case we use the ```$1``` and ```$2``` variables to define the operator ```input``` and ```measure``` arguments at runtime. The same could be applied to another argument.\n",
    "\n",
    "A dependency with respect to the previous task is set, in order to run the data import only after the container has been created. \n",
    "\n",
    "The ```on_error``` argument is set to ```abort``` so that the whole workflow stops if the tasks fails. This is the default value so it does not need to be specified for each task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = e1.newTask(name=\"Import\",\n",
    "                type=\"ophidia\",\n",
    "                operator='oph_importnc',\n",
    "                on_error='abort',\n",
    "                arguments={'measure': '$2',\n",
    "                          'container': 'example',\n",
    "                          'import_metadata': 'yes',\n",
    "                          'imp_dim': 'time', \n",
    "                          'imp_concept_level': 'd',\n",
    "                          'hierarchy': 'oph_base|oph_base|oph_time',\n",
    "                          'description': 'Imported cube', \n",
    "                          'input': '$1'},\n",
    "                dependencies={t1:''})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third task defines a *oph_subset* task to extract a portion of the datacube from the imported one.\n",
    "\n",
    "A data dependency on the import task is defined in order to use the output cube from the previous task as input to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = e1.newTask(name=\"Subset\",\n",
    "                type=\"ophidia\",\n",
    "                operator='oph_subset', \n",
    "                arguments={'subset_filter': '30:70|-20:40', \n",
    "                           'subset_dims': 'lat|lon', \n",
    "                           'subset_type': 'coord', \n",
    "                           'description': 'Subsetted cube'},\n",
    "                dependencies={t2:'cube'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the *oph_reduce* task is added to compute the average over the time series of the *Subsetted Cube*.\n",
    "\n",
    "Again a data dependency is defined in order to use the output cube from the previous task as input to this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = e1.newTask(name=\"Reduce\",\n",
    "                type=\"ophidia\",\n",
    "                operator='oph_reduce', \n",
    "                arguments={'operation': 'avg', \n",
    "                           'dim': 'time',\n",
    "                           'description': 'Reduced cube'},\n",
    "                dependencies={t3:'cube'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the workflow structure before submit it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e1.check(visual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Submit the workflow\n",
    "\n",
    "Now the ```example_workflow``` workflow can be submitted to the workflow manager, which in turn will take care of the execution of the various tasks. This can be done with the ```w1.submit()``` Python line.\n",
    "\n",
    "At this stage we need to set the values for the ```$1``` and ```$2``` variables defined for the *Import* task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = Workflow(e1)\n",
    "w1.submit(\"/home/ophidia/notebooks/tasmin_day_CMCC-CESM_rcp85_r1i1p1_20960101-21001231.nc\", \"tasmin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the experiment execution graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.monitor(frequency=1, iterative=True, visual_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns at the end of the output the status of the general workflow. If the execution was completed successfully this should be ```OPH_STATUS_COMPLETED```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the three datacubes create with the ```list``` PyOphidia function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.list(level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:7px;border-top:2px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Final remarks\n",
    "\n",
    "You've completed your first workflow with Ophidia. If you would like to get more technical info about the workflow features provided by Ophidia check the documentation [**http://ophidia.cmcc.it/documentation/users/workflow/index.html**](http://ophidia.cmcc.it/documentation/users/workflow/index.html).  \n",
    "\n",
    "Before moving to the other hands-on notebooks, clear the cube space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cube.Cube.deletecontainer(container=\"example\",force='yes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:1px;border-top:1px solid #0000FF\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now move to the last hands-on notebook [**2-Summer_days_workflow**](2-Summer_days_workflow.ipynb).\n",
    "\n",
    "If you are interested in running other workflows examples check the [**Examples**](../Examples/) folder."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
